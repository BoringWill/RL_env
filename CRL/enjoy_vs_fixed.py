import torch
import torch.nn as nn
import numpy as np
import gymnasium as gym
import os
from collections import deque
from slime_env import SlimeSelfPlayEnv, FrameStack

# --- é…ç½® ---
NEW_MODEL_PATH = "C:/Users/asus/Desktop/CRL_GPU/æ¨¡å‹é›†_opponent/train_20260125-013011/slime_ppo_vs_fixed.pth"
HISTORY_FOLDER = "æ¨¡å‹é›†_å†ä»£ç‰ˆæœ¬æœ€å¼º"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# æµ‹è¯•å‚æ•°
NUM_ENVS = 32
GAMES_PER_OPPONENT = 20  # å»ºè®®ç¨å¾®å¤šæ‰“å‡ å±€ï¼Œç»“æœæ›´å‡†


# --- æ¨¡å‹ç»“æ„ ---
class Agent(nn.Module):
    def __init__(self):
        super(Agent, self).__init__()
        # ä¿æŒç»“æ„å®Œæ•´ä»¥å…¼å®¹å„ç§æ¨¡å‹
        self.critic = nn.Sequential(
            nn.Linear(48, 256), nn.ReLU(),
            nn.Linear(256, 128), nn.ReLU(),
            nn.Linear(128, 1)
        )
        self.actor = nn.Sequential(
            nn.Linear(48, 256), nn.ReLU(),
            nn.Linear(256, 128), nn.ReLU(),
            nn.Linear(128, 4)
        )

    def get_actions(self, obs_batch, device):
        with torch.no_grad():
            t_obs = torch.as_tensor(obs_batch, dtype=torch.float32, device=device)
            logits = self.actor(t_obs)
            return torch.argmax(logits, dim=1).cpu().numpy()


def make_env():
    # æ˜¾å¼å…³é—­æ¸²æŸ“æé«˜é€Ÿåº¦
    return lambda: FrameStack(SlimeSelfPlayEnv(render_mode=None), n_frames=4)


def run_vector_battle(envs, agent_new, agent_hist, num_total_games):
    new_model_wins = 0
    games_finished = 0

    obs_p1, infos = envs.reset()
    p2_deques = [deque(maxlen=4) for _ in range(NUM_ENVS)]

    # åˆå§‹å¸§åŒæ­¥
    p2_raw_initial = infos.get("p2_raw_obs")
    for i in range(NUM_ENVS):
        init_p2 = p2_raw_initial[i] if p2_raw_initial is not None else np.zeros(12)
        for _ in range(4): p2_deques[i].append(init_p2)

    side_swapped = np.random.rand(NUM_ENVS) > 0.5

    while games_finished < num_total_games:
        obs_p2 = np.array([np.concatenate(list(d)) for d in p2_deques])

        # åˆ†é…è§‚æµ‹å€¼
        t_obs_new = np.where(side_swapped[:, None], obs_p2, obs_p1)
        t_obs_hist = np.where(side_swapped[:, None], obs_p1, obs_p2)

        # é¢„æµ‹åŠ¨ä½œ
        act_new = agent_new.get_actions(t_obs_new, DEVICE)
        act_hist = agent_hist.get_actions(t_obs_hist, DEVICE)

        # ç»„åˆåŠ¨ä½œ
        env_actions = np.zeros((NUM_ENVS, 2), dtype=np.int32)
        for i in range(NUM_ENVS):
            if not side_swapped[i]:
                env_actions[i] = [act_new[i], act_hist[i]]
            else:
                env_actions[i] = [act_hist[i], act_new[i]]

        obs_p1, _, terms, truncs, infos = envs.step(env_actions)
        p2_raw_batch = infos.get("p2_raw_obs")

        for i in range(NUM_ENVS):
            if terms[i] or truncs[i]:
                games_finished += 1
                p1_won = infos["p1_score"][i] > infos["p2_score"][i]
                p2_won = infos["p2_score"][i] > infos["p1_score"][i]

                if (not side_swapped[i] and p1_won) or (side_swapped[i] and p2_won):
                    new_model_wins += 1

                # é‡ç½®è¯¥ç¯å¢ƒçš„ P2 é˜Ÿåˆ—
                side_swapped[i] = np.random.rand() > 0.5
                p2_deques[i].clear()
                res_p2 = p2_raw_batch[i] if p2_raw_batch is not None else np.zeros(12)
                for _ in range(4): p2_deques[i].append(res_p2)

                if games_finished >= num_total_games: break
            else:
                if p2_raw_batch is not None:
                    p2_deques[i].append(p2_raw_batch[i])

    return new_model_wins


def safe_load(agent, path):
    """é€šç”¨çš„å®‰å…¨åŠ è½½å‡½æ•°"""
    if not os.path.exists(path):
        return False, "è·¯å¾„ä¸å­˜åœ¨"
    try:
        checkpoint = torch.load(path, map_location=DEVICE)
        # æå– state_dict
        if isinstance(checkpoint, dict) and "model_state_dict" in checkpoint:
            sd = checkpoint["model_state_dict"]
        else:
            sd = checkpoint

        # ä½¿ç”¨ strict=False å¿½ç•¥ä¸åŒ¹é…çš„å±‚ï¼ˆå¦‚ criticï¼‰
        msg = agent.load_state_dict(sd, strict=False)
        return True, msg
    except Exception as e:
        return False, str(e)


def main():
    print(f"æ­£åœ¨åˆå§‹åŒ– {NUM_ENVS} ä¸ªå¹¶è¡Œå¯¹æˆ˜ç¯å¢ƒ...")
    envs = gym.vector.AsyncVectorEnv([make_env() for _ in range(NUM_ENVS)])

    # 1. åŠ è½½æ–°æ¨¡å‹
    agent_new = Agent().to(DEVICE)
    success, info = safe_load(agent_new, NEW_MODEL_PATH)
    if not success:
        print(f"âŒ æ— æ³•åŠ è½½æ–°æ¨¡å‹: {info}")
        return
    print(f"âœ… æ–°æ¨¡å‹å·²å‡†å¤‡å°±ç»ª: {os.path.basename(NEW_MODEL_PATH)}")

    # 2. æ‰«æå†å²æ–‡ä»¶å¤¹
    if not os.path.exists(HISTORY_FOLDER):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶å¤¹: {HISTORY_FOLDER}")
        return

    # ä¿®æ­£ï¼šåŒæ—¶å…¼å®¹å¤§å°å†™åç¼€
    history_files = [f for f in os.listdir(HISTORY_FOLDER) if f.lower().endswith('.pth')]
    history_files.sort()

    print("=" * 70)
    print(f"å¼€å§‹å†å²æŒ‘æˆ˜èµ› | æ€»é€‰æ‰‹: {len(history_files)} | æ¯åœºå±€æ•°: {GAMES_PER_OPPONENT}")
    print("=" * 70)

    results = []
    for hist_file in history_files:
        hist_path = os.path.join(HISTORY_FOLDER, hist_file)
        agent_hist = Agent().to(DEVICE)

        success, info = safe_load(agent_hist, hist_path)
        if not success:
            print(f"âš ï¸ è·³è¿‡ {hist_file.ljust(25)} | é”™è¯¯åŸå› : {info}")
            continue

        print(f"æ­£åœ¨å¯¹é˜µ: {hist_file.ljust(25)}", end=" | ", flush=True)
        agent_hist.eval()
        agent_new.eval()

        wins = run_vector_battle(envs, agent_new, agent_hist, GAMES_PER_OPPONENT)
        win_rate = (wins / GAMES_PER_OPPONENT) * 100
        results.append((hist_file, win_rate))
        print(f"èƒœç‡: {win_rate:>6.2f}%")

    # 3. ç»“æœæ±‡æ€»
    print("\n" + "=" * 70)
    print(f"{'å†å²ç‰ˆæœ¬æ–‡ä»¶å':<35} | {'èƒœç‡':<8} | {'ç»“è®º'}")
    print("-" * 70)
    for name, rate in results:
        status = "ğŸŸ¢ èƒœå‡º" if rate > 50 else "ğŸ”´ è½è´¥"
        print(f"{name:<35} | {rate:>7.1f}% | {status}")
    print("=" * 70)

    envs.close()


if __name__ == "__main__":
    main()